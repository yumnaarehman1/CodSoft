# -*- coding: utf-8 -*-
"""movies.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HQ6GCi8Mo-TyTNI7nWqm9U_VSTVGE0rt
"""

import numpy as np

# visualization
import seaborn as sns
import matplotlib.pyplot as plt

# machine learning

from sklearn.ensemble import RandomForestClassifier

movie = pd.read_csv('movies.dat', sep='::', encoding='iso-8859-1')
 movie.columns =['MovieIDs','MovieName','Category']
 movie.dropna(inplace=True)
 movie.head()



rating = pd.read_csv('ratings.dat', sep='::', encoding='iso-8859-1')
rating.columns =['ID','MovieID','Ratings','TimeStamp']
rating.dropna(inplace=True)
rating.head()

#Data acquisition of the users dataset
user = pd.read_csv("users.dat",sep='::',encoding='iso-8859-1')
user.columns =['UserID','Gender','Age','Occupation','Zip-code']
user.dropna(inplace=True)
user.head()

movie.isna().sum()

user.isna().sum()

rating.isna().sum()



from sklearn.preprocessing import LabelEncoder
labelencoder=LabelEncoder()
user["Gender"]= labelencoder.fit_transform(user['Gender'])
user.head()

user.isna().sum()

merge_data = pd.concat([ movie, rating, user], axis=1)
merge_data.head(20)

merge_data.shape

merge_data.info()

droped_data= merge_data.drop(["Occupation", "Zip-code", "TimeStamp"],axis=1)
droped_data.head()

droped_data.isna().sum()

datafinal=  droped_data.dropna()

datafinal.shape

import seaborn as sns
sns.countplot(x=datafinal['Gender'], hue=datafinal['Ratings'])

datafinal.Age.plot.hist(bins=25)
plt.ylabel("MovieIds")
plt.xlabel("Ratings")

datafinal['Age'].plot.hist(bins=25)

sns.countplot(x=datafinal['Age'],hue=datafinal['Ratings'])

datafinal.head()

input=datafinal.drop(['Ratings', 'MovieName', 'Category', 'MovieIDs'], axis=1)
target=datafinal["Ratings"]

target.head()

input.head()

from sklearn.preprocessing import MinMaxScaler

scaler=MinMaxScaler()
scaleddata= scaler.fit_transform(input)
scaleddf = pd.DataFrame(scaleddata,columns=input.columns)
scaleddf.head()

from sklearn.model_selection import train_test_split
x_train, x_test, Y_train, Y_test=train_test_split(input, target, test_size=0.3)

Y_train

Y_test

from sklearn.linear_model import LogisticRegression
model= LogisticRegression()
model.fit(x_train,Y_train)

xtest=np.array(x_test)

modell =model.predict(x_test)

modell

Y_test











